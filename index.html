<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>JS Example</title>
    <style>
      .conversation-container {
        display: flex;
        flex-direction: column;
        gap: 10px;
        padding: 10px;
        width: calc(100vw - 40px);
        max-height: 70vh;
        overflow-y: scroll;
      }

      .conversation-container div {
        padding: 10px;
        border-radius: 5px;
        background-color: #f1f1f1;
        width: fit-content;
      }
    </style>
  </head>
  <body>
    <h1>Screen Audio and Microphone Audio</h1>
    <button id="setToken">Fetch Token</button>
    <select id="language">
      <option value="en" selected>English</option>
      <option value="hi">Hindi</option>
    </select>
    <button id="startButton">Start</button>
    <button id="stopButton" disabled>Stop</button>

    <div class="conversation-container" id="chat-container"></div>

    <script>
      const bearerToken = "HCNK7DwrVMPMlxucp16hz0tG4kAwZTOM";
      let url = "wss://eu2.rt.speechmatics.com/v2?jwt=";
      let session;
      let session2;
      let mediaRecorder;
      let mediaRecorder2;
      let seq = 0;
      let seq2 = 0;
      let jwt = "";
      let conversationLanguage = "en";
      const nullValues = ["", null, undefined];

      let message = {
        message: "StartRecognition",
        audio_format: {
          type: "file",
        },
        transcription_config: {
          language: "en",
          diarization: "speaker",
          operating_point: "enhanced",
          enable_partials: true,
          max_delay: 1,
        },
        // translation_config: {
        //   target_languages: ["en"],
        // },
      };

      document.getElementById("language").onchange = function (event) {
        const language = event.target.value;
        message.transcription_config.language = language;
        conversationLanguage = language;
        if (language === "hi") {
          message.translation_config = {
            target_languages: ["en"],
            enable_partials: true,
          };
        } else {
          delete message.translation_config;
        }
      };

      document.getElementById("setToken").onclick = async function () {
        const response = await fetch(
          "https://mp.speechmatics.com/v1/api_keys?type=rt",
          {
            method: "POST",
            headers: {
              "Content-Type": "application/json",
              Authorization: "Bearer " + bearerToken,
            },
            body: JSON.stringify({ ttl: 3600 }),
          }
        );
        const data = await response.json();
        jwt = data["key_value"];

        alert("Token fetched successfully.");
      };

      async function captureAudio() {
        document.getElementById("startButton").onclick = async function () {
          document.getElementById("startButton").disabled = true;
          document.getElementById("stopButton").disabled = false;
          document.getElementById("language").disabled = true;

          session = new WebSocket(url + jwt);
          session2 = new WebSocket(url + jwt);

          session.onopen = async () => {
            session.send(JSON.stringify(message));
            try {
              const stream = await navigator.mediaDevices.getDisplayMedia({
                //video: true,
                audio: true,
              });

              mediaRecorder = new MediaRecorder(stream);

              mediaRecorder.start(1000);

              mediaRecorder.ondataavailable = async (event) => {
                if (event.data.size > 0) {
                  const arrayBuffer = await event.data.arrayBuffer();

                  // Instead of trying to decode or convert in the browser, send the raw Opus data
                  session.send(arrayBuffer);
                }
              };
            } catch (err) {
              console.error("Error capturing audio: ", err);
            }
          };
          session.onmessage = (event) => {
            const data = JSON.parse(event.data);

            if (data && data.message === "AudioAdded") {
              seq = data.seq_no;
            }
            if (
              data &&
              conversationLanguage === "en" &&
              data.message === "AddTranscript"
            ) {
              if (!nullValues.includes(data.metadata.transcript)) {
                const div = document.createElement("div");
                div.innerHTML = `<strong>User: </strong>${data.metadata.transcript}`;
                document.getElementById("chat-container").appendChild(div);

                // Scroll to bottom
                document.getElementById("chat-container").scrollTop =
                  document.getElementById("chat-container").scrollHeight;
              }
            }

            if (
              data &&
              conversationLanguage !== "en" &&
              data.message === "AddTranslation"
            ) {
              const translation = data?.results[0]?.content;
              if (!nullValues.includes(translation)) {
                const div = document.createElement("div");
                div.innerHTML = `<strong>User: </strong>${translation}`;
                document.getElementById("chat-container").appendChild(div);

                // Scroll to bottom
                document.getElementById("chat-container").scrollTop =
                  document.getElementById("chat-container").scrollHeight;
              }
            }

            if (data && data.message === "EndOfStream") {
              session.close();
            }
          };

          session2.onopen = async () => {
            session2.send(JSON.stringify(message));
            let stream = await navigator.mediaDevices.getUserMedia({
              audio: true,
            });

            if (MediaRecorder.isTypeSupported("audio/webm")) {
              var options = {
                mimeType: "audio/webm",
                audioBitsPerSecond: 16000,
              };
            } else if (MediaRecorder.isTypeSupported("audio/mp4")) {
              var options = {
                mimeType: "audio/mp4",
                audioBitsPerSecond: 16000,
              };
            } else {
              console.error("no suitable mimetype found for this device");
            }

            mediaRecorder2 = new MediaRecorder(stream, options);

            mediaRecorder2.start(1000);

            mediaRecorder2.ondataavailable = async (event) => {
              if (event.data.size > 0) {
                const arrayBuffer = await event.data.arrayBuffer();

                session2.send(arrayBuffer);
              }
            };
          };

          session2.onmessage = (event) => {
            const data = JSON.parse(event.data);

            if (data && data.message === "AudioAdded") {
              seq2 = data.seq_no;
            }

            if (
              data &&
              conversationLanguage === "en" &&
              data.message === "AddTranscript"
            ) {
              if (!nullValues.includes(data.metadata.transcript)) {
                const div = document.createElement("div");
                div.innerHTML = `<strong>Agent: </strong>${data.metadata.transcript}`;
                document.getElementById("chat-container").appendChild(div);

                // Scroll to bottom
                document.getElementById("chat-container").scrollTop =
                  document.getElementById("chat-container").scrollHeight;
              }
            }

            if (
              data &&
              conversationLanguage !== "en" &&
              data.message === "AddTranslation"
            ) {
              const translation = data?.results[0]?.content;
              if (!nullValues.includes(translation)) {
                const div = document.createElement("div");
                div.innerHTML = `<strong>Agent: </strong>${translation}`;
                document.getElementById("chat-container").appendChild(div);

                // Scroll to bottom
                document.getElementById("chat-container").scrollTop =
                  document.getElementById("chat-container").scrollHeight;
              }
            }

            if (data && data.message === "EndOfStream") {
              session2.close();
            }
          };
        };

        document.getElementById("stopButton").onclick = function () {
          if (mediaRecorder) {
            mediaRecorder.stop();
          }
          if (mediaRecorder2) {
            mediaRecorder2.stop();
          }
          if (session) {
            const message = {
              message: "EndOfStream",
              last_seq_no: parseInt(seq, 10),
            };
            session.send(JSON.stringify(message));
          }
          if (session2) {
            const message = {
              message: "EndOfStream",
              last_seq_no: parseInt(seq2, 10),
            };
            session2.send(JSON.stringify(message));
          }

          document.getElementById("startButton").disabled = false;
          document.getElementById("stopButton").disabled = true;
          document.getElementById("language").disabled = false;

          console.log("Recording stopped.");
        };
      }
      captureAudio();
    </script>
  </body>
</html>
